
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>robotparser &#8211; インターネットスパイダーのアクセス制御 - Python Module of the Week</title>

<link rel="stylesheet" href="../_static/default.css" 
    type="text/css" />
<style>
    body {
        margin: 8px;
    }
    .highlight {
        background-color: white;
        border: 0;
    }
    .highlight pre {
        background-color: white;
    }
</style>

<link href="../_static/css/leaves.css" rel="stylesheet" type="text/css" />
<link rel="alternate" type="application/atom+xml"
      title="Doug Hellmann"
      href="http://feeds.feedburner.com/DougHellmann" />
<link rel="alternate" type="application/atom+xml"
      title="Doug Hellmann Project Releases"
      href="http://feeds.feedburner.com/DougHellmann-Releases" />
<link rel="alternate" type="application/atom+xml"
      title="Doug Hellmann Links"
      href="http://feeds.feedburner.com/DougHellmannLinkBlog" />



<script type="text/javascript">
  var DOCUMENTATION_OPTIONS = {
      URL_ROOT:    '../',
      VERSION:     '1.132',
      COLLAPSE_MODINDEX: false,
      FILE_SUFFIX: '.html'
  };
</script>

<script type="text/javascript" src="../_static/jquery.js"></script>
<script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="author" title="このドキュメントについて" href="../about.html" />
    <link rel="contents" title="コンテンツテーブル" href="../contents.html" />
    <link rel="index" title="インデックス" href="../genindex.html" />
    <link rel="top" title="Python Module of the Week" href="../index.html" />
    <link rel="up" title="ファイルフォーマット" href="../file_formats.html" />
    <link rel="next" title="暗号サービス" href="../cryptographic.html" />
    <link rel="prev" title="ConfigParser – Work with configuration files" href="../ConfigParser/index.html" />

<meta name="verify-v1" content="5saTcOa2HLac4V85yUg3SARfun1PqT5Upu7IR/6fpv4="/>
</head>
<body>
    
<div id="container">
    
<div id="header">
  <a href="/"><h1>PyMOTW</h1></a>
  <p></p>
</div>

<div id="sidebar_left_wrapper">

<div id="navigation"> 
	<ul id="navlist">
		<li><a href="../index.html">ホーム</a></li>
		<li><a href="http://blog.doughellmann.com/" target="_">ブログ</a></li>
        <li><a href="http://www.doughellmann.com/books/">書籍</a></li>
		<li><a href="../about.html">自己紹介</a></li>
		<li><a href="/2/genindex.html">サイトインデックス</a></li>
	</ul>
</div>


  <div id="sidebar_left">
      <p>この情報が役に立つと思われたら、私の本を手に取ってみてください。
      <i><a href="/books/byexample/">The Python Standard Library By
      Example</a></i>.</p>
  </div>

</div>


<div id="sidebar">
  <h3>ページコンテンツ</h3>
  <ul>
<li><a class="reference internal" href="#">robotparser &#8211; インターネットスパイダーのアクセス制御</a><ul>
<li><a class="reference internal" href="#robots-txt">robots.txt</a></li>
<li><a class="reference internal" href="#id1">シンプルなサンプル</a></li>
<li><a class="reference internal" href="#id2">長時間処理するスパイダー</a></li>
</ul>
</li>
</ul>
    <h3>ナビゲーション</h3>
      <p>
    <a href="../contents.html"><strong>コンテンツテーブル</strong></a><br/>
    
          <a href="../ConfigParser/index.html" title="前の章へ"><strong>前:</strong> ConfigParser &#8211; Work with configuration files</a><br/>
          <a href="../cryptographic.html" title="次の章へ"><strong>次:</strong> 暗号サービス</a><br/>
      </p>
    
      <h3>This Page</h3>
      <p>
      <a href="../_sources/robotparser/index.txt"
               rel="nofollow">Show Source</a>
      </p><h3>サンプルプログラム</h3>

<p>PyMOTW の全てのサンプルプログラムの出力は、
注記されていない限りは Python 2.7.2 で生成されています。
標準ライブラリの初期のバージョンでは利用できない機能も紹介している
可能性があります。</p><p><iframe src="http://rcm.amazon.com/e/cm?lt1=_blank&bc1=000000&IS2=1&bg1=DDDDDD&fc1=000000&lc1=CC6714&t=hellflynet-20&o=1&p=8&l=as1&m=amazon&f=ifr&md=10FE9736YVPPT7A0FBG2&asins=0321767349" style="width:120px;height:240px;margin:0 1em 0 1em;" scrolling="no" frameborder="0"></iframe></p>    <p class="ads">
    <script type="text/javascript"><!--
    google_ad_client = "pub-3205160560229413";
    google_ad_width = 120;
    google_ad_height = 600;
    google_ad_format = "120x600_as";
    google_ad_type = "text";
    //2007-10-27: www.doughellmann.com
    google_ad_channel = "0828653884";
    google_color_border = "FFFFFF";
    google_color_bg = "FFFFFF";
    google_color_link = "CC6714";
    google_color_text = "000000";
    google_color_url = "999999";
    google_ui_features = "rc:0";
    //-->
    </script>
    <script type="text/javascript"
      src="http://pagead2.googlesyndication.com/pagead/show_ads.js">
    </script>
    </p>
</div>


<div id="content">

    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="../cryptographic.html" title="暗号サービス"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="../ConfigParser/index.html" title="ConfigParser – Work with configuration files"
             accesskey="P">previous</a> |</li>
        <li><a href="../contents.html">PyMOTW</a> &raquo;</li>
          <li><a href="../file_formats.html" accesskey="U">ファイルフォーマット</a> &raquo;</li> 
      </ul>
    </div>

  <div class="section" id="robotparser">
<h1>robotparser &#8211; インターネットスパイダーのアクセス制御<a class="headerlink" href="#robotparser" title="Permalink to this headline">¶</a></h1>
<span class="target" id="module-robotparser"></span><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">目的:</th><td class="field-body">インターネットスパイダーを制御する robots.txt ファイルを解析する</td>
</tr>
<tr class="field"><th class="field-name">利用できるバージョン:</th><td class="field-body">2.1.3 以上</td>
</tr>
</tbody>
</table>
<p><a class="reference internal" href="#module-robotparser" title="インターネットスパイダーのアクセス制御"><tt class="xref py py-mod docutils literal"><span class="pre">robotparser</span></tt></a> は、あるユーザエージェントがリソースへアクセスできるかどうかをチェックするシンプルな仕組みを含む <tt class="docutils literal"><span class="pre">robots.txt</span></tt> ファイルフォーマットのパーサを実装します。それはスパイダー、もしくは他のクローラーアプリケーションの動作を調整したり、制限したりする必要があることを想定しています。</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last"><a class="reference internal" href="#module-robotparser" title="インターネットスパイダーのアクセス制御"><tt class="xref py py-mod docutils literal"><span class="pre">robotparser</span></tt></a> モジュールは Python 3.0 で <tt class="xref py py-mod docutils literal"><span class="pre">urllib.robotparser</span></tt> に変更されました。 <a class="reference internal" href="#module-robotparser" title="インターネットスパイダーのアクセス制御"><tt class="xref py py-mod docutils literal"><span class="pre">robotparser</span></tt></a> を使用する既存のコードは 2to3 で変更されます。</p>
</div>
<div class="section" id="robots-txt">
<h2>robots.txt<a class="headerlink" href="#robots-txt" title="Permalink to this headline">¶</a></h2>
<p><tt class="docutils literal"><span class="pre">robots.txt</span></tt> ファイルフォーマットは、web を自動徘徊してリソースへアクセスするプログラム(&#8220;スパイダー&#8221; や &#8220;クローラー&#8221; 等)向けのシンプルなテキストベースのアクセス制御システムです。そのファイルは、ユーザエージェントがアクセスする必要のない URL リスト(または URL の接頭辞)をそういったプログラム向けに提供し、ユーザエージェントの識別子を指定するレコードで構成されます。</p>
<p>これは <tt class="docutils literal"><span class="pre">http://www.doughellmann.com/</span></tt> の <tt class="docutils literal"><span class="pre">robots.txt</span></tt> ファイルです。</p>
<div class="highlight-python"><pre>User-agent: *
Disallow: /admin/
Disallow: /downloads/
Disallow: /media/
Disallow: /static/
Disallow: /codehosting/
</pre>
</div>
<p>検索エンジンが私のサイトの重いページをインデクシングしようとすると、サーバが高負荷になるので、そういったページへのアクセスを制限しています。もっと詳細なサンプルとしては <a class="reference external" href="http://www.robotstxt.org/orig.html">The Web Robots Page</a> を参照してください。</p>
</div>
<div class="section" id="id1">
<h2>シンプルなサンプル<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<p>前節のデータを使用して、シンプルなクローラが <tt class="docutils literal"><span class="pre">RobotFileParser</span></tt> の <tt class="docutils literal"><span class="pre">can_fetch()</span></tt> メソッドでページをダウンロードできるかどうかテストします。</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">robotparser</span>
<span class="kn">import</span> <span class="nn">urlparse</span>

<span class="n">AGENT_NAME</span> <span class="o">=</span> <span class="s">&#39;PyMOTW&#39;</span>
<span class="n">URL_BASE</span> <span class="o">=</span> <span class="s">&#39;http://www.doughellmann.com/&#39;</span>
<span class="n">parser</span> <span class="o">=</span> <span class="n">robotparser</span><span class="o">.</span><span class="n">RobotFileParser</span><span class="p">()</span>
<span class="n">parser</span><span class="o">.</span><span class="n">set_url</span><span class="p">(</span><span class="n">urlparse</span><span class="o">.</span><span class="n">urljoin</span><span class="p">(</span><span class="n">URL_BASE</span><span class="p">,</span> <span class="s">&#39;robots.txt&#39;</span><span class="p">))</span>
<span class="n">parser</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

<span class="n">PATHS</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s">&#39;/&#39;</span><span class="p">,</span>
    <span class="s">&#39;/PyMOTW/&#39;</span><span class="p">,</span>
    <span class="s">&#39;/admin/&#39;</span><span class="p">,</span>
    <span class="s">&#39;/downloads/PyMOTW-1.92.tar.gz&#39;</span><span class="p">,</span>
    <span class="p">]</span>

<span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">PATHS</span><span class="p">:</span>
    <span class="k">print</span> <span class="s">&#39;</span><span class="si">%6s</span><span class="s"> : </span><span class="si">%s</span><span class="s">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">parser</span><span class="o">.</span><span class="n">can_fetch</span><span class="p">(</span><span class="n">AGENT_NAME</span><span class="p">,</span> <span class="n">path</span><span class="p">),</span> <span class="n">path</span><span class="p">)</span>
    <span class="n">url</span> <span class="o">=</span> <span class="n">urlparse</span><span class="o">.</span><span class="n">urljoin</span><span class="p">(</span><span class="n">URL_BASE</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span>
    <span class="k">print</span> <span class="s">&#39;</span><span class="si">%6s</span><span class="s"> : </span><span class="si">%s</span><span class="s">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">parser</span><span class="o">.</span><span class="n">can_fetch</span><span class="p">(</span><span class="n">AGENT_NAME</span><span class="p">,</span> <span class="n">url</span><span class="p">),</span> <span class="n">url</span><span class="p">)</span>
    <span class="k">print</span>
</pre></div>
</div>
<p><tt class="docutils literal"><span class="pre">can_fetch()</span></tt> への URL 引数はそのサイトのルートへの相対パスか、完全な URL で指定します。</p>
<div class="highlight-python"><pre>$ python robotparser_simple.py
  True : /
  True : http://www.doughellmann.com/

  True : /PyMOTW/
  True : http://www.doughellmann.com/PyMOTW/

  True : /admin/
  True : http://www.doughellmann.com/admin/

 False : /downloads/PyMOTW-1.92.tar.gz
 False : http://www.doughellmann.com/downloads/PyMOTW-1.92.tar.gz</pre>
</div>
</div>
<div class="section" id="id2">
<h2>長時間処理するスパイダー<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p>リソースをダウンロードする処理に長時間かかる、もしくはダウンロード中に一時停止するように調整されたアプリケーションは、既にダウンロード済みのコンテンツの age ヘッダに基づいて定期的に新しい <tt class="docutils literal"><span class="pre">robots.txt</span></tt> ファイルをチェックすると良いです。この age の時間は自動的に制御されませんが、簡単にその時間を記録する便利なメソッドがあります。</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">robotparser</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">urlparse</span>

<span class="n">AGENT_NAME</span> <span class="o">=</span> <span class="s">&#39;PyMOTW&#39;</span>
<span class="n">parser</span> <span class="o">=</span> <span class="n">robotparser</span><span class="o">.</span><span class="n">RobotFileParser</span><span class="p">()</span>
<span class="c"># ローカルコピーを使用する</span>
<span class="n">parser</span><span class="o">.</span><span class="n">set_url</span><span class="p">(</span><span class="s">&#39;robots.txt&#39;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="n">parser</span><span class="o">.</span><span class="n">modified</span><span class="p">()</span>

<span class="n">PATHS</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s">&#39;/&#39;</span><span class="p">,</span>
    <span class="s">&#39;/PyMOTW/&#39;</span><span class="p">,</span>
    <span class="s">&#39;/admin/&#39;</span><span class="p">,</span>
    <span class="s">&#39;/downloads/PyMOTW-1.92.tar.gz&#39;</span><span class="p">,</span>
    <span class="p">]</span>

<span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">path</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">PATHS</span><span class="p">):</span>
    <span class="k">print</span>
    <span class="n">age</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">parser</span><span class="o">.</span><span class="n">mtime</span><span class="p">())</span>
    <span class="k">print</span> <span class="s">&#39;age:&#39;</span><span class="p">,</span> <span class="n">age</span><span class="p">,</span>
    <span class="k">if</span> <span class="n">age</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">print</span> <span class="s">&#39;re-reading robots.txt&#39;</span>
        <span class="n">parser</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
        <span class="n">parser</span><span class="o">.</span><span class="n">modified</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">print</span>
    <span class="k">print</span> <span class="s">&#39;</span><span class="si">%6s</span><span class="s"> : </span><span class="si">%s</span><span class="s">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">parser</span><span class="o">.</span><span class="n">can_fetch</span><span class="p">(</span><span class="n">AGENT_NAME</span><span class="p">,</span> <span class="n">path</span><span class="p">),</span> <span class="n">path</span><span class="p">)</span>
    <span class="c"># Simulate a delay in processing</span>
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>この極端なサンプルは、1秒後に新たな <tt class="docutils literal"><span class="pre">robots.txt</span></tt> ファイルをダウンロードします。</p>
<div class="highlight-python"><pre>$ python robotparser_longlived.py

age: 0
  True : /

age: 1
  True : /PyMOTW/

age: 2 re-reading robots.txt
 False : /admin/

age: 1
 False : /downloads/PyMOTW-1.92.tar.gz</pre>
</div>
<p>長時間処理するアプリケーションの &#8220;もっと良い&#8221; 実装は、そのファイルをダウンロードする前にファイル更新時刻をリクエストします。ただ、普通は <tt class="docutils literal"><span class="pre">robots.txt</span></tt> ファイルのサイズはかなり小さいので、再読み込みしてもそう大きな負荷にはなりません。</p>
<div class="admonition-see-also admonition seealso">
<p class="first admonition-title">See also</p>
<dl class="last docutils">
<dt><a class="reference external" href="http://docs.python.org/library/robotparser.html">robotparser</a></dt>
<dd>本モジュールの標準ライブラリドキュメント</dd>
<dt><a class="reference external" href="http://www.robotstxt.org/orig.html">The Web Robots Page</a></dt>
<dd>robots.txt のフォーマット説明</dd>
</dl>
</div>
</div>
</div>


    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="../cryptographic.html" title="暗号サービス"
             >next</a> |</li>
        <li class="right" >
          <a href="../ConfigParser/index.html" title="ConfigParser – Work with configuration files"
             >previous</a> |</li>
        <li><a href="../contents.html">PyMOTW</a> &raquo;</li>
          <li><a href="../file_formats.html" >ファイルフォーマット</a> &raquo;</li> 
      </ul>
    </div>



<div id="addthis"><a href="http://www.addthis.com/bookmark.php" onclick="addthis_url   = location.href; addthis_title = document.title; return addthis_click(this);" target="_blank"><img src="http://s7.addthis.com/static/btn/lg-share-en.gif" width="125" height="16" border="0" alt="Bookmark and Share" /></a><script type="text/javascript">var addthis_pub = "dhellmann";</script><script type="text/javascript" src="http://s7.addthis.com/js/widget.php?v=10"></script></div>



<!-- Disqus -->
<div id="disqus_wrapper">
<div id="disqus_thread"></div><script type="text/javascript" src="http://disqus.com/forums/doughellmann/embed.js"></script><noscript><a href="http://doughellmann.disqus.com/?url=ref">View the discussion thread.</a></noscript><a href="http://disqus.com" class="dsq-brlink">blog comments powered by <span class="logo-disqus">Disqus</span></a>
</div>

</div>

<div id="footer_ads">

    <p><script type="text/javascript"><!--
    google_ad_client = "pub-3205160560229413";
    google_ad_width = 728;
    google_ad_height = 90;
    google_ad_format = "728x90_as";
    google_ad_type = "text";
    //2007-10-21: www.doughellmann.com
    google_ad_channel = "9907726884";
    google_color_border = "FFFFFF";
    google_color_bg = "FFFFFF";
    google_color_link = "CC6714";
    google_color_text = "000000";
    google_color_url = "999999";
    google_ui_features = "rc:0";
    //-->
    </script>
    <script type="text/javascript"
      src="http://pagead2.googlesyndication.com/pagead/show_ads.js">
    </script></p>
</div>

<div id="footer">
 
<p>
    &copy; Copyright Doug Hellmann.
    | <a href="http://creativecommons.org/licenses/by-nc-sa/3.0/us/" rel="license"><img alt="Creative Commons License" style="border-width:0; align: center;" width="80" height="15" src="http://i.creativecommons.org/l/by-nc-sa/3.0/us/80x15.png"/></a>
    | Last updated on Feb 17, 2013.
   | Created using <a href="http://sphinx.pocoo.org/">Sphinx</a>.
   | Design based on "Leaves" by <a href="http://smallpark.org">SmallPark</a>
</p>
   
<script src="http://www.google-analytics.com/urchin.js" type="text/javascript" />
<script type="text/javascript">
  _uacct = "UA-1847381-1";
  urchinTracker();
</script>

</div>

</div>


<!-- Disqus -->
<script type="text/javascript">
//<![CDATA[
(function() {
		var links = document.getElementsByTagName('a');
		var query = '?';
		for(var i = 0; i < links.length; i++) {
			if(links[i].href.indexOf('#disqus_thread') >= 0) {
				query += 'url' + i + '=' + encodeURIComponent(links[i].href) + '&';
			}
		}
		document.write('<script type="text/javascript" src="http://disqus.com/forums/doughellmann/get_num_replies.js' + query + '"></' + 'script>');
	})();
//]]>
</script>


</body>
</html>